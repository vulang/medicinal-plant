{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Thống kê dữ liệu ảnh plants sau tiền xử lý\n",
        "- Metadata: `crawler/data/plants.csv`\n",
        "- Thư mục ảnh sau tiền xử lý và đã split: `image-classifier/data/{train,val,test}`\n",
        "- Notebook này tổng hợp số liệu cho từng tập train/val/test, so sánh phân bố lớp và spot-check ảnh trước khi training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette('crest')\n",
        "\n",
        "def find_path(relative_path):\n",
        "    rel = Path(relative_path)\n",
        "    cwd = Path.cwd().resolve()\n",
        "    bases = [cwd, *cwd.parents]\n",
        "    candidates = []\n",
        "    for base in bases:\n",
        "        candidates.append(base / rel)\n",
        "    for base in bases:\n",
        "        candidates.append(base / 'medicinal-plant' / rel)\n",
        "    seen = []\n",
        "    for cand in candidates:\n",
        "        if cand in seen:\n",
        "            continue\n",
        "        seen.append(cand)\n",
        "        if cand.exists():\n",
        "            return cand\n",
        "    tried = \"\\n\".join(str(p) for p in seen)\n",
        "    raise FileNotFoundError(f\"{relative_path} not found. Tried:\\n{tried}\")\n",
        "\n",
        "metadata_path = find_path('crawler/data/plants.csv')\n",
        "data_root = find_path('image-classifier/data')\n",
        "split_names = ['train', 'val', 'test']\n",
        "split_dirs = {split: data_root / split for split in split_names}\n",
        "\n",
        "project_root = metadata_path.parents[2]\n",
        "artifacts_dir = project_root / 'notebooks' / 'artifacts' / 'preprocessed'\n",
        "artifacts_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('Artifacts dir:', artifacts_dir)\n",
        "print('Working directory:', Path.cwd())\n",
        "print('Metadata path:', metadata_path)\n",
        "print('Data root:', data_root)\n",
        "for split, folder in split_dirs.items():\n",
        "    if not folder.exists():\n",
        "        raise FileNotFoundError(f\"Missing folder for split {split}: {folder}\")\n",
        "    num_classes = sum(1 for p in folder.iterdir() if p.is_dir())\n",
        "    print(f\"{split}: {num_classes} lớp ({folder})\")\n",
        "\n",
        "metadata = pd.read_csv(metadata_path)\n",
        "metadata['ID'] = metadata['ID'].astype(str)\n",
        "id_to_name = dict(zip(metadata['ID'], metadata['Plant latin name']))\n",
        "metadata.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Thống kê ban đầu\n",
        "- Số ảnh, số lớp và ảnh trung bình trên lớp của từng tập train/val/test.\n",
        "- Tổng hợp toàn bộ ảnh (train+val+test) để xem phân bố lớp.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def scan_class_counts(image_root: Path):\n",
        "    counts = {}\n",
        "    for cls_dir in sorted(image_root.iterdir()):\n",
        "        if cls_dir.is_dir():\n",
        "            n_images = sum(1 for p in cls_dir.iterdir() if p.is_file())\n",
        "            counts[cls_dir.name] = n_images\n",
        "    return counts\n",
        "\n",
        "split_counts = {split: scan_class_counts(folder) for split, folder in split_dirs.items()}\n",
        "\n",
        "split_summary = []\n",
        "for split, counts in split_counts.items():\n",
        "    total = sum(counts.values())\n",
        "    num_classes = len(counts)\n",
        "    avg = total / num_classes if num_classes else 0\n",
        "    split_summary.append(\n",
        "        {\n",
        "            'tập': split,\n",
        "            'tổng ảnh': total,\n",
        "            'số lớp': num_classes,\n",
        "            'ảnh trung bình mỗi lớp': avg,\n",
        "        }\n",
        "    )\n",
        "\n",
        "split_summary_df = pd.DataFrame(split_summary)\n",
        "display(split_summary_df)\n",
        "\n",
        "counts_frames = []\n",
        "for split, counts in split_counts.items():\n",
        "    df = (\n",
        "        pd.Series(counts, name='số ảnh')\n",
        "        .reset_index()\n",
        "        .rename(columns={'index': 'mã lớp'})\n",
        "        .assign(tên_loài=lambda df: df['mã lớp'].map(id_to_name), tập=split)\n",
        "    )\n",
        "    counts_frames.append(df)\n",
        "\n",
        "counts_by_split = (\n",
        "    pd.concat(counts_frames, ignore_index=True)\n",
        "    if counts_frames\n",
        "    else pd.DataFrame(columns=['mã lớp', 'số ảnh', 'tên_loài', 'tập'])\n",
        ")\n",
        "\n",
        "counts_df = (\n",
        "    counts_by_split.groupby('mã lớp')['số ảnh']\n",
        "    .sum()\n",
        "    .reset_index()\n",
        "    .assign(tên_loài=lambda df: df['mã lớp'].map(id_to_name))\n",
        ")\n",
        "\n",
        "total_images = counts_df['số ảnh'].sum()\n",
        "num_classes = len(counts_df)\n",
        "avg_per_class = total_images / num_classes if num_classes else 0\n",
        "\n",
        "overall_summary = pd.DataFrame(\n",
        "    {\n",
        "        'chỉ số': ['Tổng số ảnh', 'Số lớp', 'Số ảnh trung bình mỗi lớp'],\n",
        "        'giá trị': [total_images, num_classes, avg_per_class],\n",
        "    }\n",
        ")\n",
        "\n",
        "display(overall_summary)\n",
        "counts_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phân bố số lượng ảnh theo lớp\n",
        "- Histogram số ảnh mỗi lớp cho từng tập train/val/test.\n",
        "- Bar chart các lớp có nhiều ảnh nhất trên toàn bộ dữ liệu (gộp train+val+test).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if counts_by_split.empty:\n",
        "    print(\"Không có dữ liệu class để vẽ histogram.\")\n",
        "else:\n",
        "    fig_split, axes = plt.subplots(1, len(split_dirs), figsize=(16, 4), sharey=True)\n",
        "    if len(split_dirs) == 1:\n",
        "        axes = [axes]\n",
        "    for ax, split in zip(axes, split_dirs.keys()):\n",
        "        df = counts_by_split[counts_by_split['tập'] == split]\n",
        "        sns.histplot(df['số ảnh'], bins=30, ax=ax)\n",
        "        ax.set_title(f'Histogram số ảnh mỗi lớp - {split}')\n",
        "        ax.set_xlabel('Số ảnh')\n",
        "        ax.set_ylabel('Số lớp')\n",
        "    fig_split.tight_layout()\n",
        "    fig_split.savefig(artifacts_dir / 'pre_split_class_count_histogram.png', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    top_k = counts_df.sort_values('số ảnh', ascending=False).head(20)\n",
        "    fig_top, ax_top = plt.subplots(figsize=(8, 6))\n",
        "    sns.barplot(data=top_k, y='mã lớp', x='số ảnh', ax=ax_top)\n",
        "    ax_top.set_title('Top 20 lớp có nhiều ảnh nhất (train+val+test)')\n",
        "    ax_top.set_xlabel('Số ảnh')\n",
        "    ax_top.set_ylabel('Mã lớp')\n",
        "    fig_top.tight_layout()\n",
        "    fig_top.savefig(artifacts_dir / 'pre_top20_classes.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "bottom_k = counts_df.sort_values('số ảnh', ascending=True).head(20)\n",
        "bottom_k[['mã lớp', 'tên_loài', 'số ảnh']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Số lớp có ít ảnh (train+val+test)\n",
        "- Kiểm tra số lớp nằm dưới ngưỡng ảnh (mặc định 500).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if counts_df.empty:\n",
        "    print(\"Không có dữ liệu class để đếm.\")\n",
        "else:\n",
        "    threshold = 500\n",
        "    num_classes = len(counts_df)\n",
        "    num_below = (counts_df['số ảnh'] < threshold).sum()\n",
        "    pct_below = num_below / num_classes * 100 if num_classes else 0\n",
        "    print(f'{num_below}/{num_classes} lớp có ít hơn {threshold} ảnh ({pct_below:.2f}%)')\n",
        "    counts_df[counts_df['số ảnh'] < threshold]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Top 20 lớp có ít ảnh nhất (train+val+test)\n",
        "- Bar chart để xem các lớp thiếu dữ liệu.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bottom_20 = counts_df.sort_values('số ảnh', ascending=True).head(20).copy()\n",
        "bottom_20['nhãn'] = bottom_20['tên_loài'].fillna(bottom_20['mã lớp']).str.slice(0, 60)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "sns.barplot(data=bottom_20, y='nhãn', x='số ảnh', color='salmon', ax=ax)\n",
        "ax.set_title('Top 20 lớp có ít ảnh nhất')\n",
        "ax.set_xlabel('Số ảnh')\n",
        "ax.set_ylabel('Lớp / Loài')\n",
        "plt.tight_layout()\n",
        "fig.savefig(artifacts_dir / 'pre_bottom_20_classes.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ảnh trùng giữa các lớp (gộp train/val/test)\n",
        "- Đếm ảnh trùng tên xuất hiện ở nhiều lớp và top lớp bị ảnh hưởng.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if counts_df.empty:\n",
        "    print(\"Không có dữ liệu class để kiểm tra trùng ảnh.\")\n",
        "else:\n",
        "    from collections import defaultdict, Counter\n",
        "\n",
        "    file_to_classes = defaultdict(set)\n",
        "    for split, split_root in split_dirs.items():\n",
        "        for cls_dir in split_root.iterdir():\n",
        "            if cls_dir.is_dir():\n",
        "                for p in cls_dir.iterdir():\n",
        "                    if p.is_file():\n",
        "                        file_to_classes[p.name].add(cls_dir.name)\n",
        "\n",
        "    dup_files = {name: classes for name, classes in file_to_classes.items() if len(classes) > 1}\n",
        "    group_strings = sorted({', '.join(sorted(classes)) for classes in dup_files.values()})\n",
        "    if group_strings:\n",
        "        print('Nhóm lớp có ảnh trùng (mỗi dòng là danh sách lớp, phân tách dấu phẩy):')\n",
        "        for group in group_strings:\n",
        "            print(group)\n",
        "    total_dup_files = len(dup_files)\n",
        "    if total_dup_files == 0:\n",
        "        print(\"Không tìm thấy ảnh trùng tên giữa các lớp.\")\n",
        "    else:\n",
        "        class_dup_counts = Counter()\n",
        "        for classes in dup_files.values():\n",
        "            for cls in classes:\n",
        "                class_dup_counts[cls] += 1\n",
        "\n",
        "        dup_df = (\n",
        "            pd.Series(class_dup_counts, name='số ảnh trùng')\n",
        "            .sort_values(ascending=False)\n",
        "            .reset_index()\n",
        "            .rename(columns={'index': 'mã lớp'})\n",
        "        )\n",
        "        top_n = min(20, len(dup_df))\n",
        "        top = dup_df.head(top_n)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        sns.barplot(data=top, y='mã lớp', x='số ảnh trùng', color='steelblue', ax=ax)\n",
        "        ax.set_title(f'Top {top_n} lớp có nhiều ảnh trùng với lớp khác (mọi split)')\n",
        "        ax.set_xlabel('Số ảnh trùng (theo tên file)')\n",
        "        ax.set_ylabel('Mã lớp')\n",
        "        fig.tight_layout()\n",
        "        fig.savefig(artifacts_dir / 'pre_duplicates_per_class.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        print(f'Tổng số file trùng tên giữa các lớp: {total_dup_files}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Heatmap ảnh trùng giữa các lớp (train/val/test)\n",
        "- Ma trận số lượng file trùng tên giữa các cặp lớp (top lớp bị ảnh hưởng).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if counts_df.empty:\n",
        "    print('Không có dữ liệu class để vẽ heatmap trùng ảnh.')\n",
        "else:\n",
        "    from collections import defaultdict, Counter\n",
        "    from itertools import combinations\n",
        "\n",
        "    file_to_classes = defaultdict(set)\n",
        "    for split, split_root in split_dirs.items():\n",
        "        for cls_dir in split_root.iterdir():\n",
        "            if cls_dir.is_dir():\n",
        "                for p in cls_dir.iterdir():\n",
        "                    if p.is_file():\n",
        "                        file_to_classes[p.name].add(cls_dir.name)\n",
        "\n",
        "    pair_counts = Counter()\n",
        "    for classes in file_to_classes.values():\n",
        "        if len(classes) > 1:\n",
        "            for a, b in combinations(sorted(classes), 2):\n",
        "                pair_counts[(a, b)] += 1\n",
        "\n",
        "    if not pair_counts:\n",
        "        print('Không có ảnh trùng giữa các lớp.')\n",
        "    else:\n",
        "        class_totals = Counter()\n",
        "        for (a, b), c in pair_counts.items():\n",
        "            class_totals[a] += c\n",
        "            class_totals[b] += c\n",
        "        top_classes = [cls for cls, _ in class_totals.most_common(20)]\n",
        "        matrix = pd.DataFrame(0, index=top_classes, columns=top_classes, dtype=int)\n",
        "        for (a, b), c in pair_counts.items():\n",
        "            if a in matrix.index and b in matrix.columns:\n",
        "                matrix.loc[a, b] = c\n",
        "                matrix.loc[b, a] = c\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
        "        plt.title('Heatmap ảnh trùng giữa các lớp (top 20)')\n",
        "        plt.xlabel('Lớp')\n",
        "        plt.ylabel('Lớp')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(artifacts_dir / 'pre_duplicates_heatmap.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Thống kê kích thước ảnh\n",
        "- Phân bố chiều rộng, chiều cao, cạnh ngắn sau tiền xử lý (gộp train/val/test).\n",
        "- Kiểm tra số ảnh có chiều < ngưỡng (mặc định 224px).\n",
        "- Scatter width vs height để xem tỷ lệ khung hình.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "threshold = 224\n",
        "size_records = []\n",
        "read_errors = 0\n",
        "\n",
        "for split, split_root in split_dirs.items():\n",
        "    for cls_dir in split_root.iterdir():\n",
        "        if cls_dir.is_dir():\n",
        "            for p in cls_dir.iterdir():\n",
        "                if p.is_file():\n",
        "                    try:\n",
        "                        with Image.open(p) as img:\n",
        "                            w, h = img.size\n",
        "                    except Exception:\n",
        "                        read_errors += 1\n",
        "                        continue\n",
        "                    size_records.append({'class_id': cls_dir.name, 'width': w, 'height': h, 'tập': split})\n",
        "\n",
        "size_df = pd.DataFrame(size_records)\n",
        "\n",
        "if size_df.empty:\n",
        "    print('Không có dữ liệu kích thước ảnh.')\n",
        "else:\n",
        "    size_df['min_side'] = size_df[['width', 'height']].min(axis=1)\n",
        "    summary = size_df[['width', 'height', 'min_side']].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
        "    display(summary)\n",
        "\n",
        "    small = size_df[(size_df['width'] < threshold) | (size_df['height'] < threshold)]\n",
        "    num_small = len(small)\n",
        "    pct_small = num_small / len(size_df) * 100 if len(size_df) else 0\n",
        "    print(f\"{num_small}/{len(size_df)} ảnh có chiều < {threshold}px ({pct_small:.2f}%)\")\n",
        "    if read_errors:\n",
        "        print(f'Lỗi khi đọc ảnh: {read_errors}')\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "    sns.histplot(size_df['width'], bins=40, ax=axes[0])\n",
        "    axes[0].set_title('Phân bố chiều rộng')\n",
        "    axes[0].set_xlabel('Width (px)')\n",
        "    axes[0].set_ylabel('Số ảnh')\n",
        "\n",
        "    sns.histplot(size_df['height'], bins=40, ax=axes[1])\n",
        "    axes[1].set_title('Phân bố chiều cao')\n",
        "    axes[1].set_xlabel('Height (px)')\n",
        "    axes[1].set_ylabel('Số ảnh')\n",
        "\n",
        "    sns.histplot(size_df['min_side'], bins=40, ax=axes[2])\n",
        "    axes[2].set_title('Phân bố cạnh ngắn')\n",
        "    axes[2].set_xlabel('Min(width, height) (px)')\n",
        "    axes[2].set_ylabel('Số ảnh')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    sample_df = size_df.sample(min(len(size_df), 20000), random_state=0)\n",
        "    plt.figure(figsize=(7, 6))\n",
        "    sns.scatterplot(data=sample_df, x='width', y='height', s=10, alpha=0.5)\n",
        "    plt.axvline(threshold, color='red', linestyle='--', linewidth=1, label=f'Threshold {threshold}px')\n",
        "    plt.axhline(threshold, color='red', linestyle='--', linewidth=1)\n",
        "    plt.title('Scatter kích thước ảnh (width vs height)')\n",
        "    plt.xlabel('Width (px)')\n",
        "    plt.ylabel('Height (px)')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(artifacts_dir / 'pre_scatter_size.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bar chart số ảnh theo lớp (train+val+test)\n",
        "- Trục X: tên loài (hoặc mã lớp nếu thiếu tên). Trục Y: số ảnh.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_counts = counts_df.copy()\n",
        "sorted_counts['nhãn'] = sorted_counts['tên_loài'].fillna(sorted_counts['mã lớp']).str.slice(0, 60)\n",
        "sorted_counts = sorted_counts.sort_values('số ảnh', ascending=False)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(max(12, len(sorted_counts) * 0.2), 6))\n",
        "sns.barplot(data=sorted_counts, x='nhãn', y='số ảnh', color='steelblue', ax=ax)\n",
        "plt.title('Số ảnh mỗi lớp (train+val+test, sắp xếp giảm dần)')\n",
        "plt.xlabel('Loài / Lớp')\n",
        "plt.ylabel('Số ảnh')\n",
        "plt.xticks(rotation=90)\n",
        "ax.margins(x=0)\n",
        "fig.tight_layout()\n",
        "fig.savefig(artifacts_dir / 'pre_counts_per_class.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lưới ảnh ngẫu nhiên\n",
        "- Lấy mẫu nhiều lớp (mặc định từ tập train), hiển thị grid để xem trạng thái trước training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_image_paths(image_root: Path, n_samples: int = 16):\n",
        "    all_paths = []\n",
        "    for cls_dir in image_root.iterdir():\n",
        "        if cls_dir.is_dir():\n",
        "            all_paths.extend([p for p in cls_dir.iterdir() if p.is_file()])\n",
        "    random.shuffle(all_paths)\n",
        "    return all_paths[:n_samples]\n",
        "\n",
        "sample_split = 'train'\n",
        "sample_root = split_dirs[sample_split]\n",
        "sample_paths = sample_image_paths(sample_root, n_samples=16)\n",
        "\n",
        "n_cols = 4\n",
        "n_rows = int(np.ceil(len(sample_paths) / n_cols))\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 3 * n_rows))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for ax, img_path in zip(axes, sample_paths):\n",
        "    try:\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        ax.imshow(img)\n",
        "        cls_id = img_path.parent.name\n",
        "        ax.set_title(f'{sample_split} - lớp {cls_id}')\n",
        "        ax.axis('off')\n",
        "    except Exception as exc:\n",
        "        ax.axis('off')\n",
        "        ax.set_title(f'Lỗi: {exc}')\n",
        "\n",
        "for ax in axes[len(sample_paths):]:\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ảnh sau augmentation (train)\n",
        "- Lấy ngẫu nhiên vài ảnh gốc ở tập train và áp dụng pipeline augmentation (theo config training) nhiều lần để xem biến đổi.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import sys\n",
        "import yaml\n",
        "\n",
        "sys.path.append(str(project_root / 'image-classifier' / 'src'))\n",
        "from data import build_transforms, IMAGENET_MEAN, IMAGENET_STD\n",
        "\n",
        "config_path = find_path('image-classifier/config.yaml')\n",
        "cfg = yaml.safe_load(config_path.read_text())\n",
        "img_size = cfg.get('img_size', 224)\n",
        "use_timm_augment = cfg.get('use_timm_augment', False)\n",
        "\n",
        "# data_cfg tối thiểu để kích hoạt timm augmentation khi enable\n",
        "base_data_cfg = {\n",
        "    'input_size': (3, img_size, img_size),\n",
        "    'mean': IMAGENET_MEAN,\n",
        "    'std': IMAGENET_STD,\n",
        "    'interpolation': 'bicubic',\n",
        "    'crop_pct': 0.95,\n",
        "}\n",
        "train_transform = build_transforms(\n",
        "    img_size=img_size,\n",
        "    is_train=True,\n",
        "    data_cfg=base_data_cfg if use_timm_augment else None,\n",
        "    use_timm_augment=use_timm_augment,\n",
        ")\n",
        "\n",
        "# chuẩn hóa để hiển thị\n",
        "_display_mean = np.array(base_data_cfg.get('mean', IMAGENET_MEAN))\n",
        "_display_std = np.array(base_data_cfg.get('std', IMAGENET_STD))\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "    arr = tensor.detach().cpu().numpy()\n",
        "    arr = np.transpose(arr, (1, 2, 0))\n",
        "    arr = (arr * _display_std) + _display_mean\n",
        "    arr = np.clip(arr, 0, 1)\n",
        "    return arr\n",
        "\n",
        "aug_per_image = 4\n",
        "sample_paths = sample_image_paths(split_dirs['train'], n_samples=4)\n",
        "fig, axes = plt.subplots(len(sample_paths), aug_per_image + 1, figsize=(3.2 * (aug_per_image + 1), 3 * len(sample_paths)))\n",
        "\n",
        "for row, img_path in enumerate(sample_paths):\n",
        "    orig = Image.open(img_path).convert('RGB').resize((img_size, img_size))\n",
        "    cls_id = img_path.parent.name\n",
        "    axes[row, 0].imshow(orig)\n",
        "    axes[row, 0].set_title(f'gốc - lớp {cls_id}')\n",
        "    axes[row, 0].axis('off')\n",
        "\n",
        "    for i in range(aug_per_image):\n",
        "        augmented = train_transform(orig)\n",
        "        if isinstance(augmented, tuple):\n",
        "            augmented = augmented[0]\n",
        "        arr = tensor_to_image(augmented)\n",
        "        axes[row, i + 1].imshow(arr)\n",
        "        axes[row, i + 1].set_title(f'aug {i + 1}')\n",
        "        axes[row, i + 1].axis('off')\n",
        "\n",
        "fig.tight_layout()\n",
        "fig.savefig(artifacts_dir / 'pre_train_augmentations.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}