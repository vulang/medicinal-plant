{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Medicinal Plant Dataset Exploration\n",
        "\n",
        "Use this notebook to sanity-check split directories, inspect class balance, and visualize samples before training. It reads from `config.yaml` so path changes propagate automatically.\n",
        "\n",
        "What you get:\n",
        "- quick counts of valid/invalid files per split\n",
        "- class imbalance snapshots (top/bottom classes)\n",
        "- visual checks for distribution and augmentations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "pd.set_option(\"display.max_rows\", 20)\n",
        "pd.options.display.float_format = \"{:,.2f}\".format\n",
        "\n",
        "NOTEBOOK_CWD = Path.cwd().resolve()\n",
        "PROJECT_ROOT = next(\n",
        "    (\n",
        "        p\n",
        "        for p in [NOTEBOOK_CWD, NOTEBOOK_CWD.parent, NOTEBOOK_CWD.parent.parent]\n",
        "        if (p / \"config.yaml\").exists() and (p / \"src\").exists()\n",
        "    ),\n",
        "    None,\n",
        ")\n",
        "if PROJECT_ROOT is None:\n",
        "    raise RuntimeError(\"Unable to locate project root. Please run the notebook from within the repository.\")\n",
        "\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "with open(PROJECT_ROOT / \"config.yaml\", \"r\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "SOURCE_DIR = PROJECT_ROOT / cfg.get(\"source_dir\", \"source\")\n",
        "SPLITS = {\n",
        "    \"source\": SOURCE_DIR,\n",
        "}\n",
        "DEFAULT_SPLIT = next(iter(SPLITS))\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n",
        "print(f\"Source root: {SOURCE_DIR}\")\n",
        "cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.data import _is_valid_image\n",
        "\n",
        "records = []\n",
        "missing_splits = []\n",
        "\n",
        "for split_name, split_path in SPLITS.items():\n",
        "    if not split_path.exists():\n",
        "        missing_splits.append(split_name)\n",
        "        continue\n",
        "\n",
        "    for cls_dir in sorted(p for p in split_path.iterdir() if p.is_dir()):\n",
        "        total_files = 0\n",
        "        valid_files = 0\n",
        "        for file_path in cls_dir.iterdir():\n",
        "            if not file_path.is_file():\n",
        "                continue\n",
        "            total_files += 1\n",
        "            if _is_valid_image(str(file_path)):\n",
        "                valid_files += 1\n",
        "\n",
        "        records.append(\n",
        "            {\n",
        "                \"split\": split_name,\n",
        "                \"class_id\": cls_dir.name,\n",
        "                \"total_files\": total_files,\n",
        "                \"valid_files\": valid_files,\n",
        "                \"invalid_files\": total_files - valid_files,\n",
        "            }\n",
        "        )\n",
        "\n",
        "counts_df = pd.DataFrame(records)\n",
        "display(counts_df.head(10))\n",
        "\n",
        "if missing_splits:\n",
        "    print(f\"[WARN] missing split directories: {', '.join(missing_splits)}\")\n",
        "elif counts_df.empty:\n",
        "    print(\"[WARN] no data found. Check config paths above.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if counts_df.empty:\n",
        "    print(\"No split data to summarize.\")\n",
        "else:\n",
        "    split_summary = (\n",
        "        counts_df\n",
        "        .groupby(\"split\")[\n",
        "            [\"total_files\", \"valid_files\", \"invalid_files\"]\n",
        "        ]\n",
        "        .sum()\n",
        "        .assign(valid_pct=lambda df: 100 * df[\"valid_files\"] / df[\"total_files\"])\n",
        "        .round(2)\n",
        "        .sort_index()\n",
        "    )\n",
        "\n",
        "    class_dirs = counts_df.groupby(\"split\")[\"class_id\"].nunique().rename(\"class_dirs\")\n",
        "    non_empty_classes = (\n",
        "        counts_df[counts_df[\"valid_files\"] > 0]\n",
        "        .groupby(\"split\")[\"class_id\"]\n",
        "        .nunique()\n",
        "        .rename(\"classes_with_images\")\n",
        "    )\n",
        "    coverage = pd.concat([class_dirs, non_empty_classes], axis=1).fillna(0).astype(int)\n",
        "\n",
        "    print(\"Per-split totals (valid vs invalid files):\")\n",
        "    display(split_summary)\n",
        "\n",
        "    print(\"Per-split class coverage:\")\n",
        "    display(coverage)\n",
        "\n",
        "    class_totals = (\n",
        "        counts_df\n",
        "        .groupby(\"class_id\")[[\"valid_files\", \"invalid_files\"]]\n",
        "        .sum()\n",
        "        .sort_values(\"valid_files\", ascending=False)\n",
        "    )\n",
        "    print(\"Top classes by valid images (all splits combined):\")\n",
        "    display(class_totals.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if counts_df.empty:\n",
        "    print(\"No class distribution to inspect.\")\n",
        "else:\n",
        "    primary_split = DEFAULT_SPLIT\n",
        "    split_counts = counts_df[counts_df[\"split\"] == primary_split].sort_values(\"valid_files\", ascending=False)\n",
        "    if split_counts.empty:\n",
        "        print(f\"{primary_split} split is empty; skipping class balance preview.\")\n",
        "    else:\n",
        "        top10 = split_counts.head(10)[[\"class_id\", \"valid_files\", \"invalid_files\"]]\n",
        "        bottom10 = split_counts.tail(10).sort_values(\"valid_files\")[[\"class_id\", \"valid_files\", \"invalid_files\"]]\n",
        "\n",
        "        print(f\"Largest {primary_split} classes (by valid files):\")\n",
        "        display(top10.reset_index(drop=True))\n",
        "\n",
        "        print(f\"Smallest {primary_split} classes (by valid files):\")\n",
        "        display(bottom10.reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if counts_df.empty:\n",
        "    print(\"No data to plot.\")\n",
        "else:\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "    totals = counts_df.groupby(\"split\")[['valid_files', 'invalid_files']].sum()\n",
        "    if not totals.empty:\n",
        "        totals.plot(kind=\"bar\", stacked=True, ax=axes[0], color=[\"#2a9d8f\", \"#e76f51\"])\n",
        "        axes[0].set_title(\"Valid vs invalid images by split\")\n",
        "        axes[0].set_ylabel(\"images\")\n",
        "        axes[0].legend(loc=\"upper right\")\n",
        "    else:\n",
        "        axes[0].axis(\"off\")\n",
        "        axes[0].set_title(\"No split totals\")\n",
        "\n",
        "    split_names = list(SPLITS.keys())\n",
        "    palette = plt.cm.tab10.colors\n",
        "    for split, color in zip(split_names, palette):\n",
        "        subset = counts_df[counts_df[\"split\"] == split][\"valid_files\"]\n",
        "        if not subset.empty:\n",
        "            axes[1].hist(subset, bins=20, alpha=0.65, label=split, color=color)\n",
        "    axes[1].set_title(\"Per-class valid image counts\")\n",
        "    axes[1].set_xlabel(\"images per class\")\n",
        "    axes[1].set_ylabel(\"frequency\")\n",
        "    axes[1].legend()\n",
        "\n",
        "    primary_split = DEFAULT_SPLIT\n",
        "    primary_counts = counts_df[counts_df[\"split\"] == primary_split].sort_values(\"valid_files\")\n",
        "    if primary_counts.empty:\n",
        "        axes[2].axis(\"off\")\n",
        "        axes[2].set_title(\"No data\")\n",
        "    else:\n",
        "        tail = primary_counts.head(min(5, len(primary_counts)))\n",
        "        head = primary_counts.tail(min(5, len(primary_counts)))\n",
        "        combined = pd.concat([tail, head])\n",
        "        axes[2].barh(combined[\"class_id\"], combined[\"valid_files\"], color=\"#457b9d\")\n",
        "        axes[2].set_title(f\"{primary_split}: smallest vs largest classes\")\n",
        "        axes[2].set_xlabel(\"valid images\")\n",
        "        axes[2].invert_yaxis()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Class distribution shares\n",
        "\n",
        "How much of each split is dominated by a handful of classes? The chart below shows the proportion of images contributed by the top classes (everything beyond the top 15 is grouped under `other`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if counts_df.empty:\n",
        "    print(\"No class distribution to plot.\")\n",
        "else:\n",
        "    ncols = len(SPLITS)\n",
        "    fig, axes = plt.subplots(1, ncols, figsize=(7 * ncols, 5))\n",
        "    if ncols == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for ax, (split, _) in zip(axes, SPLITS.items()):\n",
        "        subset = counts_df[counts_df[\"split\"] == split].sort_values(\"valid_files\", ascending=False)\n",
        "        if subset.empty:\n",
        "            ax.axis(\"off\")\n",
        "            ax.set_title(f\"{split} (no data)\")\n",
        "            continue\n",
        "\n",
        "        total_valid = subset[\"valid_files\"].sum()\n",
        "        top = subset.head(15)\n",
        "        other_count = subset.iloc[15:][\"valid_files\"].sum()\n",
        "\n",
        "        labels = list(top[\"class_id\"])\n",
        "        shares = list((top[\"valid_files\"] / total_valid * 100).round(2))\n",
        "        if other_count > 0:\n",
        "            labels.append(\"other\")\n",
        "            shares.append(round(other_count / total_valid * 100, 2))\n",
        "\n",
        "        ax.barh(labels[::-1], shares[::-1], color=\"#2a9d8f\")\n",
        "        ax.set_title(f\"{split}: share of images by class\")\n",
        "        ax.set_xlabel(\"% of split\")\n",
        "        ax.set_xlim(0, max(shares) * 1.15)\n",
        "\n",
        "    plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imbalance spotlight\n",
        "\n",
        "Two quick visuals to surface long-tail issues:\n",
        "- **Cumulative share**: how many classes account for 80-90% of images.\n",
        "- **Count ratio**: how class image counts compare to the median (log-scaled).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if counts_df.empty:\n",
        "    print(\"No data for imbalance charts.\")\n",
        "else:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(18, 5))\n",
        "\n",
        "    split_names = list(SPLITS.keys())\n",
        "    palette = plt.cm.tab10.colors\n",
        "\n",
        "    # Cumulative share per split (Lorenz-style)\n",
        "    for split, color in zip(split_names, palette):\n",
        "        subset = (\n",
        "            counts_df[(counts_df[\"split\"] == split) & (counts_df[\"valid_files\"] > 0)]\n",
        "            .sort_values(\"valid_files\", ascending=False)\n",
        "        )\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        counts = subset[\"valid_files\"].to_numpy()\n",
        "        cumulative = (counts.cumsum() / counts.sum()) * 100\n",
        "        x = range(1, len(counts) + 1)\n",
        "\n",
        "        axes[0].plot(x, cumulative, marker=\"o\", markersize=3, label=f\"{split} ({len(counts)} classes)\", color=color)\n",
        "\n",
        "        for threshold in (80, 90):\n",
        "            idx = next((i for i, v in enumerate(cumulative, start=1) if v >= threshold), None)\n",
        "            if idx:\n",
        "                axes[0].axvline(idx, color=color, linestyle=\"--\", alpha=0.25)\n",
        "                axes[0].text(idx, threshold + 2, f\"{threshold}% in {idx} classes\", color=color, ha=\"right\", va=\"bottom\", fontsize=9)\n",
        "\n",
        "    axes[0].set_title(\"Cumulative share of images by class rank\")\n",
        "    axes[0].set_xlabel(\"class rank (most to least images)\")\n",
        "    axes[0].set_ylabel(\"% of split covered\")\n",
        "    axes[0].set_ylim(0, 105)\n",
        "    axes[0].grid(alpha=0.2)\n",
        "    axes[0].legend()\n",
        "\n",
        "    # Distribution of class counts vs median for the primary split\n",
        "    primary_split = DEFAULT_SPLIT\n",
        "    primary_counts = counts_df[(counts_df[\"split\"] == primary_split) & (counts_df[\"valid_files\"] > 0)]\n",
        "    if primary_counts.empty:\n",
        "        axes[1].axis(\"off\")\n",
        "        axes[1].set_title(\"Split empty\")\n",
        "    else:\n",
        "        ratios = primary_counts[\"valid_files\"] / primary_counts[\"valid_files\"].median()\n",
        "        axes[1].hist(ratios, bins=25, color=\"#264653\", alpha=0.85)\n",
        "        axes[1].axvline(1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
        "        axes[1].set_xscale(\"log\")\n",
        "        axes[1].set_title(f\"{primary_split} class counts vs median (log scale)\")\n",
        "        axes[1].set_xlabel(\"count / median count\")\n",
        "        axes[1].set_ylabel(\"number of classes\")\n",
        "\n",
        "        max_min_ratio = primary_counts[\"valid_files\"].max() / primary_counts[\"valid_files\"].min()\n",
        "        axes[1].text(0.98, 0.95, f\"max/min: {max_min_ratio:.1f}x\", transform=axes[1].transAxes, ha=\"right\", va=\"top\", fontsize=9, bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.7))\n",
        "\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Photo counts and aspect ratios\n",
        "\n",
        "Number of photos per class (across all splits) and how the images are shaped (width/height). Useful for catching skewed classes or unusual crops before training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_profiles = []\n",
        "load_errors = []\n",
        "\n",
        "for split_name, split_path in SPLITS.items():\n",
        "    if not split_path.exists():\n",
        "        continue\n",
        "\n",
        "    for img_path in split_path.rglob('*'):\n",
        "        if not img_path.is_file():\n",
        "            continue\n",
        "        if not _is_valid_image(str(img_path)):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                width, height = img.size\n",
        "        except Exception as exc:\n",
        "            load_errors.append((img_path, str(exc)))\n",
        "            continue\n",
        "\n",
        "        image_profiles.append(\n",
        "            {\n",
        "                'split': split_name,\n",
        "                'class_id': img_path.parent.name,\n",
        "                'path': str(img_path.relative_to(PROJECT_ROOT)),\n",
        "                'width': width,\n",
        "                'height': height,\n",
        "            }\n",
        "        )\n",
        "\n",
        "image_dims_df = pd.DataFrame(image_profiles)\n",
        "if image_dims_df.empty:\n",
        "    print('No images found to profile.')\n",
        "else:\n",
        "    image_dims_df['aspect_ratio'] = image_dims_df['width'] / image_dims_df['height']\n",
        "    print(f\"Profiled {len(image_dims_df)} images across {image_dims_df['split'].nunique()} splits.\")\n",
        "    if load_errors:\n",
        "        print(f\"[WARN] skipped {len(load_errors)} files that failed to open.\")\n",
        "    display(image_dims_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_dims_df.empty:\n",
        "    print('No image stats to summarize.')\n",
        "else:\n",
        "    per_class_counts = (\n",
        "        image_dims_df\n",
        "        .groupby('class_id')\n",
        "        .size()\n",
        "        .sort_values(ascending=False)\n",
        "        .rename('image_count')\n",
        "    )\n",
        "\n",
        "    # Bar chart: class on x-axis, count on y-axis\n",
        "    fig, ax = plt.subplots(figsize=(20, 6))\n",
        "    ax.bar(per_class_counts.index, per_class_counts.values, color='#2a9d8f')\n",
        "    ax.set_title('Images per class')\n",
        "    ax.set_xlabel('class id')\n",
        "    ax.set_ylabel('number of photos')\n",
        "    ax.tick_params(axis='x', rotation=90, labelsize=7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Histogram for distribution overview\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    ax.hist(per_class_counts, bins=40, color='#264653', alpha=0.85)\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_title('Image count per class (log bins)')\n",
        "    ax.set_xlabel('images per class')\n",
        "    ax.set_ylabel('number of classes')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print('Photo count per class (all splits):')\n",
        "    display(per_class_counts.head(15).to_frame())\n",
        "    display(per_class_counts.tail(15).to_frame())\n",
        "\n",
        "    aspect_summary = (\n",
        "        image_dims_df\n",
        "        .groupby('split')['aspect_ratio']\n",
        "        .describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
        "        .rename(columns={'50%': 'median', '10%': 'p10', '90%': 'p90', '25%': 'p25', '75%': 'p75'})\n",
        "        .round(3)\n",
        "    )\n",
        "\n",
        "    print('Aspect ratio summary by split:')\n",
        "    display(aspect_summary)\n",
        "\n",
        "    orientation_bins = (\n",
        "        image_dims_df\n",
        "        .assign(\n",
        "            orientation=pd.cut(\n",
        "                image_dims_df['aspect_ratio'],\n",
        "                bins=[0, 0.9, 1.1, float('inf')],\n",
        "                labels=['tall', 'square-ish', 'wide'],\n",
        "                include_lowest=True,\n",
        "            )\n",
        "        )\n",
        "        .groupby(['split', 'orientation'])\n",
        "        .size()\n",
        "        .unstack(fill_value=0)\n",
        "    )\n",
        "\n",
        "    print('Orientation counts (width/height):')\n",
        "    display(orientation_bins)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_dims_df.empty:\n",
        "    print('No class distribution charts to plot.')\n",
        "else:\n",
        "    per_class_counts = (\n",
        "        image_dims_df\n",
        "        .groupby('class_id')\n",
        "        .size()\n",
        "        .sort_values(ascending=False)\n",
        "        .rename('image_count')\n",
        "    )\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(22, 6))\n",
        "\n",
        "    # Histogram of class sizes (log-scaled)\n",
        "    axes[0].hist(per_class_counts, bins=40, color='#264653', alpha=0.85)\n",
        "    axes[0].set_xscale('log')\n",
        "    axes[0].set_title('Image count per class (log bins)')\n",
        "    axes[0].set_xlabel('images per class')\n",
        "    axes[0].set_ylabel('classes')\n",
        "\n",
        "    # Top/bottom classes\n",
        "    top_n = min(20, len(per_class_counts))\n",
        "    top = per_class_counts.head(top_n)\n",
        "    bottom = per_class_counts.tail(top_n)\n",
        "\n",
        "    axes[1].barh(top.index[::-1], top.values[::-1], color='#2a9d8f')\n",
        "    axes[1].set_title(f'Top {top_n} classes by images')\n",
        "    axes[1].set_xlabel('image count')\n",
        "    axes[1].invert_yaxis()\n",
        "\n",
        "    axes[2].barh(bottom.index, bottom.values, color='#e76f51')\n",
        "    axes[2].set_title(f'Bottom {top_n} classes by images')\n",
        "    axes[2].set_xlabel('image count')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Orientation stacked bars by split\n",
        "    orientation_bins = (\n",
        "        image_dims_df\n",
        "        .assign(\n",
        "            orientation=pd.cut(\n",
        "                image_dims_df['aspect_ratio'],\n",
        "                bins=[0, 0.9, 1.1, float('inf')],\n",
        "                labels=['tall', 'square-ish', 'wide'],\n",
        "                include_lowest=True,\n",
        "            )\n",
        "        )\n",
        "        .groupby(['split', 'orientation'])\n",
        "        .size()\n",
        "        .unstack(fill_value=0)\n",
        "    )\n",
        "\n",
        "    orientation_bins.plot(kind='bar', stacked=True, figsize=(10, 5), color=['#1d3557', '#a8dadc', '#e63946'])\n",
        "    plt.title('Orientation mix by split')\n",
        "    plt.ylabel('images')\n",
        "    plt.xlabel('split')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if image_dims_df.empty:\n",
        "    print('No aspect ratios to visualize.')\n",
        "else:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "    split_names = list(SPLITS.keys())\n",
        "    palette = plt.cm.tab10.colors\n",
        "\n",
        "    for split, color in zip(split_names, palette):\n",
        "        subset = image_dims_df[image_dims_df['split'] == split]['aspect_ratio']\n",
        "        if subset.empty:\n",
        "            continue\n",
        "        axes[0].hist(subset, bins=40, alpha=0.6, label=split, color=color)\n",
        "\n",
        "    axes[0].set_title('Aspect ratio (width/height) by split')\n",
        "    axes[0].set_xlabel('aspect ratio')\n",
        "    axes[0].set_ylabel('images')\n",
        "    axes[0].legend()\n",
        "\n",
        "    if len(image_dims_df) > 0:\n",
        "        sample_n = min(len(image_dims_df), 3000)\n",
        "        sample = image_dims_df.sample(n=sample_n, random_state=0)\n",
        "        axes[1].scatter(sample['width'], sample['height'], s=10, alpha=0.4, color='#457b9d')\n",
        "        axes[1].set_title('Width vs height (sample)')\n",
        "        axes[1].set_xlabel('width (px)')\n",
        "        axes[1].set_ylabel('height (px)')\n",
        "        axes[1].grid(alpha=0.2)\n",
        "    else:\n",
        "        axes[1].axis('off')\n",
        "        axes[1].set_title('No samples')\n",
        "\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from src.data import build_transforms, IMAGENET_MEAN, IMAGENET_STD\n",
        "\n",
        "transform = build_transforms(cfg[\"img_size\"], is_train=True)\n",
        "mean = torch.tensor(cfg.get(\"data_cfg\", {}).get(\"mean\", IMAGENET_MEAN)).view(3, 1, 1)\n",
        "std = torch.tensor(cfg.get(\"data_cfg\", {}).get(\"std\", IMAGENET_STD)).view(3, 1, 1)\n",
        "\n",
        "def _denormalize(img_tensor):\n",
        "    return img_tensor * std + mean\n",
        "\n",
        "def show_random_sample(split=DEFAULT_SPLIT, n=4, seed=None, apply_transform=True):\n",
        "    rng = random.Random(seed)\n",
        "    split_path = SPLITS.get(split)\n",
        "    if split_path is None or not split_path.exists():\n",
        "        raise ValueError(f\"Unknown or missing split: {split}\")\n",
        "\n",
        "    class_dirs = [p for p in split_path.iterdir() if p.is_dir()]\n",
        "    if not class_dirs:\n",
        "        raise RuntimeError(f\"No class directories found in {split_path}\")\n",
        "\n",
        "    valid_images = [p for p in split_path.rglob(\"*\") if p.is_file() and _is_valid_image(str(p))]\n",
        "    if not valid_images:\n",
        "        raise RuntimeError(f\"No valid images found in {split_path}\")\n",
        "\n",
        "    chosen = rng.sample(valid_images, k=min(n, len(valid_images)))\n",
        "    cols = 2 if apply_transform else 1\n",
        "    fig, axes = plt.subplots(len(chosen), cols, figsize=(6 * cols, 3 * len(chosen)), squeeze=False)\n",
        "\n",
        "    for ax_row, img_path in zip(axes, chosen):\n",
        "        pil_image = Image.open(img_path).convert(\"RGB\")\n",
        "        ax_row[0].imshow(pil_image)\n",
        "        ax_row[0].set_title(f\"Original: {img_path.parent.name}\")\n",
        "        ax_row[0].axis(\"off\")\n",
        "\n",
        "        if apply_transform:\n",
        "            tensor_image = transform(pil_image)\n",
        "            vis_tensor = _denormalize(tensor_image).permute(1, 2, 0).clamp(0, 1)\n",
        "            ax_row[1].imshow(vis_tensor)\n",
        "            ax_row[1].set_title(\"Transformed (train pipeline)\")\n",
        "            ax_row[1].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "show_random_sample(DEFAULT_SPLIT, n=3, seed=0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}