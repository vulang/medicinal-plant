{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medicinal Plant Dataset Exploration\n",
    "\n",
    "Use this notebook to sanity-check split directories, inspect class balance, and visualize samples before training. It reads from `config.yaml` so path changes propagate automatically.\n",
    "\n",
    "What you get:\n",
    "- quick counts of valid/invalid files per split\n",
    "- class imbalance snapshots (top/bottom classes)\n",
    "- visual checks for distribution and augmentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "NOTEBOOK_CWD = Path.cwd().resolve()\n",
    "PROJECT_ROOT = next(\n",
    "    (\n",
    "        p\n",
    "        for p in [NOTEBOOK_CWD, NOTEBOOK_CWD.parent, NOTEBOOK_CWD.parent.parent]\n",
    "        if (p / \"config.yaml\").exists() and (p / \"src\").exists()\n",
    "    ),\n",
    "    None,\n",
    ")\n",
    "if PROJECT_ROOT is None:\n",
    "    raise RuntimeError(\"Unable to locate project root. Please run the notebook from within the repository.\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "with open(PROJECT_ROOT / \"config.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "DATA_ROOT = PROJECT_ROOT / cfg.get(\"data_dir\", \"data\")\n",
    "SPLITS = {\n",
    "    \"train\": PROJECT_ROOT / cfg.get(\"train_dir\", \"data/train\"),\n",
    "    \"val\": PROJECT_ROOT / cfg.get(\"val_dir\", \"data/val\"),\n",
    "    \"test\": PROJECT_ROOT / cfg.get(\"test_dir\", \"data/test\"),\n",
    "}\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data root: {DATA_ROOT}\")\n",
    "cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import _is_valid_image\n",
    "\n",
    "records = []\n",
    "missing_splits = []\n",
    "\n",
    "for split_name, split_path in SPLITS.items():\n",
    "    if not split_path.exists():\n",
    "        missing_splits.append(split_name)\n",
    "        continue\n",
    "\n",
    "    for cls_dir in sorted(p for p in split_path.iterdir() if p.is_dir()):\n",
    "        total_files = 0\n",
    "        valid_files = 0\n",
    "        for file_path in cls_dir.iterdir():\n",
    "            if not file_path.is_file():\n",
    "                continue\n",
    "            total_files += 1\n",
    "            if _is_valid_image(str(file_path)):\n",
    "                valid_files += 1\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                \"split\": split_name,\n",
    "                \"class_id\": cls_dir.name,\n",
    "                \"total_files\": total_files,\n",
    "                \"valid_files\": valid_files,\n",
    "                \"invalid_files\": total_files - valid_files,\n",
    "            }\n",
    "        )\n",
    "\n",
    "counts_df = pd.DataFrame(records)\n",
    "display(counts_df.head(10))\n",
    "\n",
    "if missing_splits:\n",
    "    print(f\"[WARN] missing split directories: {', '.join(missing_splits)}\")\n",
    "elif counts_df.empty:\n",
    "    print(\"[WARN] no data found. Check config paths above.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_df.empty:\n",
    "    print(\"No split data to summarize.\")\n",
    "else:\n",
    "    split_summary = (\n",
    "        counts_df\n",
    "        .groupby(\"split\")[\n",
    "            [\"total_files\", \"valid_files\", \"invalid_files\"]\n",
    "        ]\n",
    "        .sum()\n",
    "        .assign(valid_pct=lambda df: 100 * df[\"valid_files\"] / df[\"total_files\"])\n",
    "        .round(2)\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    class_dirs = counts_df.groupby(\"split\")[\"class_id\"].nunique().rename(\"class_dirs\")\n",
    "    non_empty_classes = (\n",
    "        counts_df[counts_df[\"valid_files\"] > 0]\n",
    "        .groupby(\"split\")[\"class_id\"]\n",
    "        .nunique()\n",
    "        .rename(\"classes_with_images\")\n",
    "    )\n",
    "    coverage = pd.concat([class_dirs, non_empty_classes], axis=1).fillna(0).astype(int)\n",
    "\n",
    "    print(\"Per-split totals (valid vs invalid files):\")\n",
    "    display(split_summary)\n",
    "\n",
    "    print(\"Per-split class coverage:\")\n",
    "    display(coverage)\n",
    "\n",
    "    class_totals = (\n",
    "        counts_df\n",
    "        .groupby(\"class_id\")[[\"valid_files\", \"invalid_files\"]]\n",
    "        .sum()\n",
    "        .sort_values(\"valid_files\", ascending=False)\n",
    "    )\n",
    "    print(\"Top classes by valid images (all splits combined):\")\n",
    "    display(class_totals.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_df.empty:\n",
    "    print(\"No class distribution to inspect.\")\n",
    "else:\n",
    "    train_counts = counts_df[counts_df[\"split\"] == \"train\"].sort_values(\"valid_files\", ascending=False)\n",
    "    if train_counts.empty:\n",
    "        print(\"Train split is empty; skipping class balance preview.\")\n",
    "    else:\n",
    "        top10 = train_counts.head(10)[[\"class_id\", \"valid_files\", \"invalid_files\"]]\n",
    "        bottom10 = train_counts.tail(10).sort_values(\"valid_files\")[[\"class_id\", \"valid_files\", \"invalid_files\"]]\n",
    "\n",
    "        print(\"Largest train classes (by valid files):\")\n",
    "        display(top10.reset_index(drop=True))\n",
    "\n",
    "        print(\"Smallest train classes (by valid files):\")\n",
    "        display(bottom10.reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_df.empty:\n",
    "    print(\"No data to plot.\")\n",
    "else:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    totals = counts_df.groupby(\"split\")[[\"valid_files\", \"invalid_files\"]].sum()\n",
    "    if not totals.empty:\n",
    "        totals.plot(kind=\"bar\", stacked=True, ax=axes[0], color=[\"#2a9d8f\", \"#e76f51\"])\n",
    "        axes[0].set_title(\"Valid vs invalid images by split\")\n",
    "        axes[0].set_ylabel(\"images\")\n",
    "        axes[0].legend(loc=\"upper right\")\n",
    "    else:\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[0].set_title(\"No split totals\")\n",
    "\n",
    "    for split, color in [(\"train\", \"#264653\"), (\"val\", \"#2a9d8f\")]:\n",
    "        subset = counts_df[counts_df[\"split\"] == split][\"valid_files\"]\n",
    "        if not subset.empty:\n",
    "            axes[1].hist(subset, bins=20, alpha=0.65, label=split, color=color)\n",
    "    axes[1].set_title(\"Per-class valid image counts\")\n",
    "    axes[1].set_xlabel(\"images per class\")\n",
    "    axes[1].set_ylabel(\"frequency\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    train_counts = counts_df[counts_df[\"split\"] == \"train\"].sort_values(\"valid_files\")\n",
    "    if train_counts.empty:\n",
    "        axes[2].axis(\"off\")\n",
    "        axes[2].set_title(\"No train data\")\n",
    "    else:\n",
    "        tail = train_counts.head(min(5, len(train_counts)))\n",
    "        head = train_counts.tail(min(5, len(train_counts)))\n",
    "        combined = pd.concat([tail, head])\n",
    "        axes[2].barh(combined[\"class_id\"], combined[\"valid_files\"], color=\"#457b9d\")\n",
    "        axes[2].set_title(\"Train: smallest vs largest classes\")\n",
    "        axes[2].set_xlabel(\"valid images\")\n",
    "        axes[2].invert_yaxis()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class distribution shares\n",
    "\n",
    "How much of each split is dominated by a handful of classes? The chart below shows the proportion of images contributed by the top classes (everything beyond the top 15 is grouped under `other`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_df.empty:\n",
    "    print(\"No class distribution to plot.\")\n",
    "else:\n",
    "    ncols = len(SPLITS)\n",
    "    fig, axes = plt.subplots(1, ncols, figsize=(7 * ncols, 5))\n",
    "    if ncols == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, (split, _) in zip(axes, SPLITS.items()):\n",
    "        subset = counts_df[counts_df[\"split\"] == split].sort_values(\"valid_files\", ascending=False)\n",
    "        if subset.empty:\n",
    "            ax.axis(\"off\")\n",
    "            ax.set_title(f\"{split} (no data)\")\n",
    "            continue\n",
    "\n",
    "        total_valid = subset[\"valid_files\"].sum()\n",
    "        top = subset.head(15)\n",
    "        other_count = subset.iloc[15:][\"valid_files\"].sum()\n",
    "\n",
    "        labels = list(top[\"class_id\"])\n",
    "        shares = list((top[\"valid_files\"] / total_valid * 100).round(2))\n",
    "        if other_count > 0:\n",
    "            labels.append(\"other\")\n",
    "            shares.append(round(other_count / total_valid * 100, 2))\n",
    "\n",
    "        ax.barh(labels[::-1], shares[::-1], color=\"#2a9d8f\")\n",
    "        ax.set_title(f\"{split}: share of images by class\")\n",
    "        ax.set_xlabel(\"% of split\")\n",
    "        ax.set_xlim(0, max(shares) * 1.15)\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalance spotlight\n",
    "\n",
    "Two quick visuals to surface long-tail issues:\n",
    "- **Cumulative share**: how many classes account for 80-90% of images.\n",
    "- **Count ratio**: how class image counts compare to the median (log-scaled).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_df.empty:\n",
    "    print(\"No data for imbalance charts.\")\n",
    "else:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 5))\n",
    "\n",
    "    # Cumulative share per split (Lorenz-style)\n",
    "    for split, color in [(\"train\", \"#2a9d8f\"), (\"val\", \"#e76f51\")]:\n",
    "        subset = (\n",
    "            counts_df[(counts_df[\"split\"] == split) & (counts_df[\"valid_files\"] > 0)]\n",
    "            .sort_values(\"valid_files\", ascending=False)\n",
    "        )\n",
    "        if subset.empty:\n",
    "            continue\n",
    "\n",
    "        counts = subset[\"valid_files\"].to_numpy()\n",
    "        cumulative = (counts.cumsum() / counts.sum()) * 100\n",
    "        x = range(1, len(counts) + 1)\n",
    "\n",
    "        axes[0].plot(x, cumulative, marker=\"o\", markersize=3, label=f\"{split} ({len(counts)} classes)\", color=color)\n",
    "\n",
    "        for threshold in (80, 90):\n",
    "            idx = next((i for i, v in enumerate(cumulative, start=1) if v >= threshold), None)\n",
    "            if idx:\n",
    "                axes[0].axvline(idx, color=color, linestyle=\"--\", alpha=0.25)\n",
    "                axes[0].text(idx, threshold + 2, f\"{threshold}% in {idx} classes\", color=color, ha=\"right\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "    axes[0].set_title(\"Cumulative share of images by class rank\")\n",
    "    axes[0].set_xlabel(\"class rank (most to least images)\")\n",
    "    axes[0].set_ylabel(\"% of split covered\")\n",
    "    axes[0].set_ylim(0, 105)\n",
    "    axes[0].grid(alpha=0.2)\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Distribution of class counts vs median (train split)\n",
    "    train_counts = counts_df[(counts_df[\"split\"] == \"train\") & (counts_df[\"valid_files\"] > 0)]\n",
    "    if train_counts.empty:\n",
    "        axes[1].axis(\"off\")\n",
    "        axes[1].set_title(\"Train split empty\")\n",
    "    else:\n",
    "        ratios = train_counts[\"valid_files\"] / train_counts[\"valid_files\"].median()\n",
    "        axes[1].hist(ratios, bins=25, color=\"#264653\", alpha=0.85)\n",
    "        axes[1].axvline(1, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "        axes[1].set_xscale(\"log\")\n",
    "        axes[1].set_title(\"Train class counts vs median (log scale)\")\n",
    "        axes[1].set_xlabel(\"count / median count\")\n",
    "        axes[1].set_ylabel(\"number of classes\")\n",
    "\n",
    "        max_min_ratio = train_counts[\"valid_files\"].max() / train_counts[\"valid_files\"].min()\n",
    "        axes[1].text(0.98, 0.95, f\"max/min: {max_min_ratio:.1f}x\", transform=axes[1].transAxes, ha=\"right\", va=\"top\", fontsize=9, bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"white\", alpha=0.7))\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.data import build_transforms, IMAGENET_MEAN, IMAGENET_STD\n",
    "\n",
    "transform = build_transforms(cfg[\"img_size\"], is_train=True)\n",
    "mean = torch.tensor(cfg.get(\"data_cfg\", {}).get(\"mean\", IMAGENET_MEAN)).view(3, 1, 1)\n",
    "std = torch.tensor(cfg.get(\"data_cfg\", {}).get(\"std\", IMAGENET_STD)).view(3, 1, 1)\n",
    "\n",
    "def _denormalize(img_tensor):\n",
    "    return img_tensor * std + mean\n",
    "\n",
    "def show_random_sample(split=\"train\", n=4, seed=None, apply_transform=True):\n",
    "    rng = random.Random(seed)\n",
    "    split_path = SPLITS.get(split)\n",
    "    if split_path is None or not split_path.exists():\n",
    "        raise ValueError(f\"Unknown or missing split: {split}\")\n",
    "\n",
    "    class_dirs = [p for p in split_path.iterdir() if p.is_dir()]\n",
    "    if not class_dirs:\n",
    "        raise RuntimeError(f\"No class directories found in {split_path}\")\n",
    "\n",
    "    valid_images = [p for p in split_path.rglob(\"*\") if p.is_file() and _is_valid_image(str(p))]\n",
    "    if not valid_images:\n",
    "        raise RuntimeError(f\"No valid images found in {split_path}\")\n",
    "\n",
    "    chosen = rng.sample(valid_images, k=min(n, len(valid_images)))\n",
    "    cols = 2 if apply_transform else 1\n",
    "    fig, axes = plt.subplots(len(chosen), cols, figsize=(6 * cols, 3 * len(chosen)), squeeze=False)\n",
    "\n",
    "    for ax_row, img_path in zip(axes, chosen):\n",
    "        pil_image = Image.open(img_path).convert(\"RGB\")\n",
    "        ax_row[0].imshow(pil_image)\n",
    "        ax_row[0].set_title(f\"Original: {img_path.parent.name}\")\n",
    "        ax_row[0].axis(\"off\")\n",
    "\n",
    "        if apply_transform:\n",
    "            tensor_image = transform(pil_image)\n",
    "            vis_tensor = _denormalize(tensor_image).permute(1, 2, 0).clamp(0, 1)\n",
    "            ax_row[1].imshow(vis_tensor)\n",
    "            ax_row[1].set_title(\"Transformed (train pipeline)\")\n",
    "            ax_row[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "show_random_sample(\"train\", n=3, seed=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
