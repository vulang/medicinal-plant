# Training configuration
seed: 42
data_dir: data
train_dir: data/train
val_dir: data/val
test_dir: data/test

img_size: 224
batch_size: 32
num_workers: 2

model_name: resnet18   # choices: resnet18, resnet50, efficientnet_b0, mobilenet_v3_small, convnext_tiny/small/base/large, convnextv2_base.fcmae_ft_in22k_in1k
pretrained: true
use_timm_augment: false   # set true to use timm's RandomResizedCrop-style augmentation (more aggressive)

epochs: 40
learning_rate: 0.0005
weight_decay: 0.0001
label_smoothing: 0.1
warmup_epochs: 5
warmup_epochs_phase1: 3
patience: 10
use_amp: true
max_grad_norm: 1.0
finetune_lr: null        # set to a float (e.g., 0.0001) to drop LR before fine-tuning all layers

device: cuda           # auto | cpu | cuda | mps
save_dir: models
outputs_dir: outputs

mlflow:
  enabled: true
  tracking_uri: null      # e.g., http://127.0.0.1:5000 or leave null for local ./mlruns
  experiment_name: medicinal-plants
  run_name: null          # optionally override per run
  artifact_subdir: checkpoints
